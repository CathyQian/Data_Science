{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides feature engineering for data. Here the feature engineering includes \n",
    "- Naive feature engineering to get sum, average and counts of some features\n",
    "- Extract key words from features and map these key words into binary values (0, 1)\n",
    "- Special designation for building_ids, manager_ids, display_address with only 1 observation, change into -1\n",
    "- High-Cardinality Categorical encoding\n",
    "- Factorize building_id, display_address, manager_id, street_address\n",
    "\n",
    "Core code from rakhlin, another Python version of It is lit by Branden\n",
    "  https://www.kaggle.com/rakhlin/another-python-version-of-it-is-lit-by-branden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    ''' naive engineering\n",
    "    '''\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    df[\"photo_count\"] = df[\"photos\"].apply(len)\n",
    "    \n",
    "    df[\"street_address\"] = df['street_address'].apply(fmt)\n",
    "    df[\"display_address\"] = df[\"display_address\"].apply(fmt)\n",
    "    df[\"desc_wordcount\"] = df[\"description\"].apply(str.split).apply(len)\n",
    "    \n",
    "    df[\"pricePerBed\"] = df['price'] / df['bedrooms']\n",
    "    df[\"pricePerBath\"] = df['price'] / df['bathrooms']\n",
    "    df[\"pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    \n",
    "    df[\"bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
    "    df[\"bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
    "    df[\"bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
    "    df[\"bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
    "    \n",
    "    # FE_0 to FE_6 don't process NAN.\n",
    "    df = df.fillna(-1).replace(np.inf, -1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorize(df1, df2, column):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    ''' Encode input values as an enumerated type or categorical variable (i.e., 0, 1, 2,â€¦..)\n",
    "    Return the unique values. Index is returned when passed values is Index or Series\n",
    "    '''\n",
    "    factors = ps.factorize()[0]\n",
    "    df1[column] = factors[:len(df1)]\n",
    "    df2[column] = factors[len(df1):]\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def designate_single_observations(df1, df2, column):\n",
    "    '''designate single observations into -1\n",
    "    '''\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hcc_encode(train_df, test_df, variable, target, prior_prob, k, f=1, g=1, r_k=None, update_df=None):\n",
    "    \"\"\"\n",
    "    See \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in\n",
    "    Classification and Prediction Problems\" by Daniele Micci-Barreca\n",
    "    \"\"\"\n",
    "    hcc_name = \"_\".join([\"hcc\", variable, target])\n",
    "\n",
    "    grouped = train_df.groupby(variable)[target].agg({\"size\": \"size\", \"mean\": \"mean\"})\n",
    "    grouped[\"lambda\"] = 1 / (g + np.exp((k - grouped[\"size\"]) / f))\n",
    "    grouped[hcc_name] = grouped[\"lambda\"] * grouped[\"mean\"] + (1 - grouped[\"lambda\"]) * prior_prob\n",
    "\n",
    "    df = test_df[[variable]].join(grouped, on = variable, how = \"left\")[hcc_name].fillna(prior_prob)\n",
    "    if r_k: df *= np.random.uniform(1 - r_k, 1 + r_k, len(test_df))     # Add uniform noise. Not mentioned in original paper\n",
    "\n",
    "    if update_df is None: update_df = test_df\n",
    "    if hcc_name not in update_df.columns: update_df[hcc_name] = np.nan\n",
    "    update_df.update(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_binary_features(df):\n",
    "    '''Extract key words from features and create binary columns including features in bows, with values either 0 or 1\n",
    "    This is very similar to what I did in statistical analysis or mapping in FE2\n",
    "    '''\n",
    "    bows = {\n",
    "        \"dogs\": (\"dogs\", \"dog\"),\n",
    "        \"cats\": (\"cats\",),\n",
    "        \"nofee\": (\"no fee\", \"no-fee\", \"no  fee\", \"nofee\", \"no_fee\"),\n",
    "        \"lowfee\": (\"reduced_fee\", \"low_fee\", \"reduced fee\", \"low fee\"),\n",
    "        \"furnished\": (\"furnished\",),\n",
    "        \"parquet\": (\"parquet\", \"hardwood\"),\n",
    "        \"concierge\": (\"concierge\", \"doorman\", \"housekeep\", \"in_super\"),\n",
    "        \"prewar\": (\"prewar\", \"pre_war\", \"pre war\", \"pre-war\"),\n",
    "        \"laundry\": (\"laundry\", \"lndry\"),\n",
    "        \"health\": (\"health\", \"gym\", \"fitness\", \"training\"),\n",
    "        \"transport\": (\"train\", \"subway\", \"transport\"),\n",
    "        \"parking\": (\"parking\",),\n",
    "        \"utilities\": (\"utilities\", \"heat water\", \"water included\")\n",
    "    }\n",
    "    def indicator(bow):\n",
    "        return lambda s: int(any([x in s for x in bow]))\n",
    "\n",
    "    features = df[\"features\"].apply(lambda f: \" \".join(f).lower())\n",
    "    for key in bows:\n",
    "        df[\"feature_\" + key] = features.apply(indicator(bows[key]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Here both \"listing_id\" and 'created' represents the order when the post was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_json(\"train.json\")\n",
    "X_test = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make target integer, one hot encoded, calculate target priors\n",
    "X_train = X_train.replace({\"interest_level\": {\"low\": 0, \"medium\": 1, \"high\": 2}})\n",
    "X_train = X_train.join(pd.get_dummies(X_train[\"interest_level\"], prefix=\"pred\").astype(int))\n",
    "prior_0, prior_1, prior_2 = X_train[[\"pred_0\", \"pred_1\", \"pred_2\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add common features\n",
    "X_train = add_features(X_train)\n",
    "X_test = add_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Special designation for building_ids, manager_ids, display_address with only 1 observation, change into -1\n",
    "for col in ('building_id', 'manager_id', 'display_address'):\n",
    "    X_train, X_test = designate_single_observations(X_train, X_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# High-Cardinality Categorical encoding\n",
    "skf = StratifiedKFold(5)\n",
    "attributes = product((\"building_id\", \"manager_id\"), zip((\"pred_1\", \"pred_2\"), (prior_1, prior_2)))\n",
    "for variable, (target, prior) in attributes:\n",
    "    hcc_encode(X_train, X_test, variable, target, prior, k=5, r_k=None)\n",
    "    for train, test in skf.split(np.zeros(len(X_train)), X_train['interest_level']):\n",
    "        hcc_encode(X_train.iloc[train], X_train.iloc[test], variable, target, prior, k=5, r_k=0.01, update_df=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Factorize building_id, display_address, manager_id, street_address\n",
    "for col in ('building_id', 'display_address', 'manager_id', 'street_address'):\n",
    "    # encode col into numerical values starting from 0, 1, 2,....\n",
    "    X_train, X_test = factorize(X_train, X_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create binarized features\n",
    "X_train = create_binary_features(X_train)\n",
    "X_test = create_binary_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"photos\", \"pred_0\",\"pred_1\", \"pred_2\", \"description\",\"building_id\", \"features\", \"created\"], axis = 1)\n",
    "X_test = X_test.drop([\"photos\", \"description\",\"building_id\", \"features\", \"created\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_json('FE6_train.json')\n",
    "X_test.to_json('FE6_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
