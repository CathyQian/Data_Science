{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is very important in most machine learning problems.\n",
    "\n",
    "The following code used continuous & categorical features to encode some 'important' features, especially manager_id. The code was partially copied from Little Boat: https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/32123\n",
    "The following algorithms and public log loss for the test dataset are achieved:\n",
    "\n",
    "- random forests: 0.62909\n",
    "- xgboost: 0.60205\n",
    "- logistic regression: 1.52583\n",
    "- Gaussian Naive Bayes: 3.49425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"train.json\")\n",
    "test_df = pd.read_json(\"test.json\")\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test_df[\"listing_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define get_stats function\n",
    "- It first merge train_df and test_df, followed by grouping the dataframe by group_column, then calculating the count, mean, std, median, max, min of the target_column feature.\n",
    "- It returns the train and test df with the newly added columns as numpy array (selected_train, selected_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(train_df, test_df, target_column, group_column = 'manager_id'):\n",
    "    '''\n",
    "    target_column: numeric columns to group with (e.g. price, bedrooms, bathrooms)\n",
    "    group_column: categorical columns to group on (e.g. manager_id, building_id)\n",
    "    '''\n",
    "    train_df['row_id'] = range(train_df.shape[0])\n",
    "    test_df['row_id'] = range(test_df.shape[0])\n",
    "    train_df['train'] = 1\n",
    "    test_df['train'] = 0\n",
    "    all_df = train_df[['row_id', 'train', target_column, group_column]].append(test_df[['row_id','train', target_column, group_column]])\n",
    "    all_df = all_df.reindex()\n",
    "    grouped = all_df[[target_column, group_column]].groupby(group_column)\n",
    "    \n",
    "    the_size = pd.DataFrame(grouped.size()).reset_index()\n",
    "    the_size.columns = [group_column, '%s_size' % target_column]\n",
    "    \n",
    "    the_mean = pd.DataFrame(grouped.mean()).reset_index()\n",
    "    the_mean.columns = [group_column, '%s_mean' % target_column]\n",
    "    \n",
    "    the_std = pd.DataFrame(grouped.std()).reset_index().fillna(0)\n",
    "    the_std.columns = [group_column, '%s_std' % target_column]\n",
    "    \n",
    "    the_median = pd.DataFrame(grouped.median()).reset_index()\n",
    "    the_median.columns = [group_column, '%s_median' % target_column]\n",
    "    \n",
    "    the_stats = pd.merge(the_size, the_mean)\n",
    "    the_stats = pd.merge(the_stats, the_std)\n",
    "    the_stats = pd.merge(the_stats, the_median)\n",
    "\n",
    "    the_max = pd.DataFrame(grouped.max()).reset_index()\n",
    "    the_max.columns = [group_column, '%s_max' % target_column]\n",
    "    \n",
    "    the_min = pd.DataFrame(grouped.min()).reset_index()\n",
    "    the_min.columns = [group_column, '%s_min' % target_column]\n",
    "\n",
    "    the_stats = pd.merge(the_stats, the_max)\n",
    "    the_stats = pd.merge(the_stats, the_min)\n",
    "\n",
    "    all_df = pd.merge(all_df, the_stats)\n",
    "\n",
    "    selected_train = all_df[all_df['train'] == 1]\n",
    "    selected_test = all_df[all_df['train'] == 0]\n",
    "    \n",
    "    selected_train.sort_values('row_id', inplace=True)\n",
    "    selected_test.sort_values('row_id', inplace=True)\n",
    "    \n",
    "    selected_train.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "    selected_test.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "\n",
    "    return np.array(selected_train), np.array(selected_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the get_stats function\n",
    "\n",
    "The following code set group_column = 'manager_id', scan target_id = 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', and return train_stack_list and test_stack_list both with dimension of (6, 49352, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# target_column\n",
    "selected_manager_id_proj = ['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price']\n",
    "\n",
    "train_stack_list = []\n",
    "test_stack_list = []\n",
    "\n",
    "# group column = 'manager_id'\n",
    "for target_col in selected_manager_id_proj:\n",
    "    tmp_train, tmp_test = get_stats(train_df, test_df, target_column=target_col)\n",
    "    # dimension of tmp_train is (49352, 6)\n",
    "    train_stack_list.append(tmp_train)\n",
    "    test_stack_list.append(tmp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code set group_column = 'bedrooms', scan target_id = 'price', 'listing_id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "selected_bedrooms_proj = ['price', 'listing_id']\n",
    "\n",
    "for target_col in selected_bedrooms_proj:\n",
    "    tmp_train, tmp_test = get_stats(train_df, test_df, target_column=target_col, group_column='bedrooms')\n",
    "    train_stack_list.append(tmp_train)\n",
    "    test_stack_list.append(tmp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 49352, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_stack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 74659, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_stack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.set_index([[i for i in range(len(train_df))]])\n",
    "test_df = test_df.set_index([[i for i in range(len(test_df))]])\n",
    "\n",
    "for i in range(7):\n",
    "    train_add = pd.DataFrame(train_stack_list[i],  columns = ['size_{0}'.format(i), 'mean_{0}'.format(i), 'std_{0}'.format(i),\n",
    "                                                              'median_{0}'.format(i), 'max_{0}'.format(i), 'min_{0}'.format(i)])\n",
    "    test_add = pd.DataFrame(test_stack_list[i],  columns = ['size_{0}'.format(i), 'mean_{0}'.format(i), 'std_{0}'.format(i), \n",
    "                                                            'median_{0}'.format(i), 'max_{0}'.format(i), 'min_{0}'.format(i)])\n",
    "    train_add = train_add.set_index([[i for i in range(len(train_add))]])\n",
    "    test_add = test_add.set_index([[i for i in range(len(test_add))]])\n",
    "    train_df = pd.concat([train_df, train_add], axis = 1)\n",
    "    test_df = pd.concat([test_df, test_add], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureE(df):\n",
    "    df[\"num_photos\"] = df[\"photos\"].apply(len)\n",
    "    df[\"num_features\"] = df[\"features\"].apply(len)\n",
    "    df[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "    df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "    df[\"created_year\"] = df[\"created\"].dt.year\n",
    "    df[\"created_month\"] = df[\"created\"].dt.month\n",
    "    df[\"created_day\"] = df[\"created\"].dt.day\n",
    "    df = df.drop(['photos', 'features', 'description', 'listing_id', 'created', 'building_id', 'manager_id', 'display_address', 'street_address'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = featureE(train_df)\n",
    "test_df = featureE(test_df)\n",
    "y = train_df['interest_level']\n",
    "train_df = train_df.drop(['interest_level', 'row_id', 'train', 'created_year'], axis = 1)\n",
    "test_df = test_df.drop(['row_id', 'train', 'created_year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = 0.30\n",
    "seed = 2018\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x, y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64070518969863688"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_val_pred = clf.predict_proba(X_validation)\n",
    "log_loss(Y_validation, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = clf.predict_proba(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low', 'medium'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2idx = {label: i for i, label in enumerate(clf.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in [\"high\", \"low\", \"medium\"]:\n",
    "    sub[label] = y[:, labels2idx[label]]\n",
    "sub.to_csv(\"ml_3_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public score: 0.62909\n",
    "Private score: 0.62976"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [49352, 74659]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-43150b9fd6fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvalidation_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.30\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2018\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1660\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [49352, 74659]"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "validation_size = 0.30\n",
    "seed = 2018\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x, y, test_size = validation_size, random_state = seed)\n",
    "\n",
    "model = XGBClassifier()\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learning_rate = learning_rate)\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 2018)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring = 'neg_log_loss', n_jobs = 1, cv = kfold)\n",
    "result = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"BestL %f using %s\" % (- result.best_score_, result.best_params_))\n",
    "means, stdevs = [], []\n",
    "for params, mean_score, scores in result.grid_scores_:\n",
    "    stdev = scores.std()\n",
    "    means.append(- mean_score)\n",
    "    stdevs.append(stdev)\n",
    "    print(\"%f (%f) with: %r\" %(- mean_score, stdev, params))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model = XGBClassifier(learning_rate = 0.3)\n",
    "model.fit(X_train, Y_train)\n",
    "print(model.feature_importances_)\n",
    "\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = test_df[train_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = model.predict_proba(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels2idx = {label: i for i, label in enumerate(model.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y[:, labels2idx[label]]\n",
    "sub.to_csv(\"ml_3_xgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private score: 0.60389\n",
    "Public score: 0.60205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71912043179077489"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "validation_size = 0.30\n",
    "seed = 2018\n",
    "y = y.map({'high':0, 'medium':1, 'low':2})\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x, y, test_size = validation_size, random_state = seed)\n",
    "clf = LogisticRegression(tol = 1e-8, fit_intercept = True, random_state = 5, max_iter = 1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_val_pred = clf.predict_proba(X_validation)\n",
    "log_loss(Y_validation, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(test_df.values)\n",
    "labels2idx = {label: i for i, label in enumerate(clf.classes_)}\n",
    "labels2idx = {'high': 0, 'low': 1, 'medium': 2}\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred[:, labels2idx[label]]\n",
    "sub.to_csv(\"ml_3_lr.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public score: 1.52583\n",
    "Private score: 1.52764\n",
    "\n",
    "Logistic regression performs really bad here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "train_df = pd.read_json(\"train.json\")\n",
    "y = train_df['interest_level']\n",
    "\n",
    "validation_size = 0.30\n",
    "seed = 2018\n",
    "y = y.map({'high':0, 'medium':1, 'low':2})\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x, y, test_size = validation_size, random_state = seed)\n",
    "clf = GaussianNB(priors = None)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(test_df.values)\n",
    "labels2idx = {label: i for i, label in enumerate(clf.classes_)}\n",
    "labels2idx = {'high': 0, 'low': 1, 'medium': 2}\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred[:, labels2idx[label]]\n",
    "sub.to_csv(\"ml_3_nb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private score: 3.57894\n",
    "Public score: 3.49425\n",
    "\n",
    "Gaussian Naive Bayes performs bad here. Probably the naive independent assumption doesn't hold for the features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
