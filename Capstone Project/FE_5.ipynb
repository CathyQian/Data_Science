{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides feature engineering for data after being cleaned. Here the feature engineering includes \n",
    "- Naive feature engineering to get sum, average and counts of some features\n",
    "- get_stats function from Little Boat: https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/32123\n",
    "- modified from FE_1, added moreFE function and more features are encoded via get_stats function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Naive Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naiveFE(df):\n",
    "    ''' do naive feature engineering to both the train and test data frame\n",
    "    '''\n",
    "    # total number of room\n",
    "    df[\"sum_room\"] = df[\"bedrooms\"] + df[\"bathrooms\"]\n",
    "    df[\"room_diff\"] = df[\"bedrooms\"] - df[\"bathrooms\"]\n",
    "    \n",
    "    # average price per room (withnan)\n",
    "    df[\"price_s\"] = df[\"price\"]/df[\"sum_room\"]\n",
    "    df[\"price_bed\"] = df[\"price\"]/df[\"bedrooms\"]\n",
    "    df[\"price_bath\"] = df[\"price\"]/df[\"bathrooms\"]\n",
    "    \n",
    "    # number of photos\n",
    "    df[\"num_photos\"] = df[\"photos\"].apply(len)\n",
    "    \n",
    "    # number features\n",
    "    df[\"num_features\"] = df[\"features\"].apply(len)\n",
    "    \n",
    "    # count of words present in description column\n",
    "    df[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "    \n",
    "    # created time, year = 2016 constant\n",
    "    df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "    df[\"created_month\"] = df[\"created\"].dt.month\n",
    "    df[\"created_day\"] = df[\"created\"].dt.day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = naiveFE(train)\n",
    "test_df = naiveFE(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_stats function\n",
    "\n",
    "#### Define get_stats function\n",
    "It first merge train_df and test_df, followed by grouping the dataframe by group_column (especially manager_id), then calculating the count, mean, std, median, max, min of the target_column feature. It returns the train and test df with the newly added columns as numpy array (selected_train, selected_test).\n",
    "\n",
    "The following code was adapted from Little Boat: https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/32123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(train_df, test_df, target_column, group_column = 'manager_id'):\n",
    "    '''\n",
    "    target_column: numeric columns to group with (e.g. price, bedrooms, bathrooms)\n",
    "    group_column: categorical columns to group on (e.g. manager_id, building_id)\n",
    "    '''\n",
    "    train_df['row_id'] = range(train_df.shape[0])\n",
    "    test_df['row_id'] = range(test_df.shape[0])\n",
    "    train_df['train'] = 1\n",
    "    test_df['train'] = 0\n",
    "    all_df = train_df[['row_id', 'train', target_column, group_column]].append(test_df[['row_id','train', target_column, group_column]])\n",
    "    all_df = all_df.reindex()\n",
    "    grouped = all_df[[target_column, group_column]].groupby(group_column)\n",
    "    \n",
    "    the_size = pd.DataFrame(grouped.size()).reset_index()\n",
    "    the_size.columns = [group_column, '%s_size' % target_column]\n",
    "    \n",
    "    the_mean = pd.DataFrame(grouped.mean()).reset_index()\n",
    "    the_mean.columns = [group_column, '%s_mean' % target_column]\n",
    "    \n",
    "    the_std = pd.DataFrame(grouped.std()).reset_index().fillna(0)\n",
    "    the_std.columns = [group_column, '%s_std' % target_column]\n",
    "    \n",
    "    the_median = pd.DataFrame(grouped.median()).reset_index()\n",
    "    the_median.columns = [group_column, '%s_median' % target_column]\n",
    "    \n",
    "    the_stats = pd.merge(the_size, the_mean)\n",
    "    the_stats = pd.merge(the_stats, the_std)\n",
    "    the_stats = pd.merge(the_stats, the_median)\n",
    "\n",
    "    the_max = pd.DataFrame(grouped.max()).reset_index()\n",
    "    the_max.columns = [group_column, '%s_max' % target_column]\n",
    "    \n",
    "    the_min = pd.DataFrame(grouped.min()).reset_index()\n",
    "    the_min.columns = [group_column, '%s_min' % target_column]\n",
    "\n",
    "    the_stats = pd.merge(the_stats, the_max)\n",
    "    the_stats = pd.merge(the_stats, the_min)\n",
    "\n",
    "    all_df = pd.merge(all_df, the_stats)\n",
    "\n",
    "    selected_train = all_df[all_df['train'] == 1]\n",
    "    selected_test = all_df[all_df['train'] == 0]\n",
    "    \n",
    "    selected_train.sort_values('row_id', inplace=True)\n",
    "    selected_test.sort_values('row_id', inplace=True)\n",
    "    \n",
    "    selected_train.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "    selected_test.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "\n",
    "    return np.array(selected_train), np.array(selected_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the get_stats function\n",
    "The following code set group_column = 'manager_id' or 'building_id', scan target_id = 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'price' and update train_df and test_df correspondently.\n",
    "\n",
    "Note:The SettingWithCopyWarning is to show users that they may be operating on a copy and not the original as they think. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Feature Engineering for get_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def moreFE(df):\n",
    "    #'bad_addr' \n",
    "    \n",
    "    # extract time from 'created' column\n",
    "    df['weekday'] = df[\"created\"].dt.dayofweek\n",
    "    df['day_of_year'] = df[\"created\"].dt.dayofyear\n",
    "    df['hour'] = df[\"created\"].dt.hour \n",
    "        \n",
    "    # ratio of bed number to bath number\n",
    "    df['bed_to_bath'] = df['bedrooms']/df['bathrooms']\n",
    "    \n",
    "    # count of building_id appearing in the train and testing dataset \n",
    "    building_counts = pd.DataFrame(df.groupby(['building_id'])['building_id'].count(), columns=['building_id'])\n",
    "    building_counts['index0'] = building_counts.index\n",
    "    building_counts = np.array(building_counts)\n",
    "    \n",
    "    bld_counts = {}\n",
    "    for i in range(len(building_counts)):\n",
    "        bld_counts[building_counts[i][1]] = building_counts[i][0]\n",
    "   \n",
    "    bld_id = np.array(df['building_id'])\n",
    "    bld_count_list = []\n",
    "    for i in range(len(bld_id)):\n",
    "        bld_count_list.append(bld_counts[bld_id[i]])\n",
    "    df['bldg_count'] = bld_count_list\n",
    "    '''    \n",
    "    'zero_bldg'\n",
    "    'latitude_grid'\n",
    "    'longitude_grid' \n",
    "    'lat_long_grid'\n",
    "    '''\n",
    "    return df\n",
    "\n",
    "#y = train_df['interest']\n",
    "#all_df = train_df.append(test_df)\n",
    "#all_df = moreFE(all_df)\n",
    "#train_df = all_df[0:]\n",
    "train_df = moreFE(train_df)\n",
    "test_df = moreFE(test_df)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_stack_list = []\n",
    "test_stack_list = []\n",
    "column_name_list = []\n",
    "\n",
    "selected_manager_id_proj = ['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', 'listing_id',\n",
    "                   'created_month', 'created_day', 'num_features', 'price_bed', 'price_bath', 'sum_room', 'room_diff',\n",
    "                   'num_photos','num_description_words','weekday', 'day_of_year', 'hour', 'bed_to_bath', 'bldg_count']\n",
    "\n",
    "for target_col in selected_manager_id_proj:\n",
    "    tmp_train, tmp_test = get_stats(train_df, test_df, target_column = target_col, group_column = 'manager_id')\n",
    "    tmp_name = target_col + '_' + 'manager_id'\n",
    "    tmp_name_list = [tmp_name + '_count', tmp_name + '_mean', tmp_name + '_std', tmp_name + '_median', tmp_name + '_max', tmp_name + '_min']\n",
    "    train_stack_list.append(tmp_train)\n",
    "    test_stack_list.append(tmp_test)\n",
    "    column_name_list.append(tmp_name_list)\n",
    "\n",
    "selected_bedrooms_proj = ['price', 'listing_id', 'created_month', 'num_features', 'weekday', 'day_of_year', 'hour', 'bldg_count']\n",
    "\n",
    "for target_col in selected_bedrooms_proj:\n",
    "    tmp_train, tmp_test = get_stats(train_df, test_df, target_column=target_col, group_column='bedrooms')\n",
    "    tmp_name = target_col + '_' + 'bedrooms'\n",
    "    tmp_name_list = [tmp_name + '_count', tmp_name + '_mean', tmp_name + '_std', tmp_name + '_median', tmp_name + '_max', tmp_name + '_min']\n",
    "    train_stack_list.append(tmp_train)\n",
    "    test_stack_list.append(tmp_test)\n",
    "    column_name_list.append(tmp_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add engineered statistics into original train_df and test_df\n",
    "\n",
    "Both train_stack_list and test_stack_list are of dimension (10, 49352, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_stack_list)):\n",
    "    stat = pd.DataFrame(train_stack_list[i], columns = column_name_list[i])\n",
    "    stat['row_id'] = range(stat.shape[0])\n",
    "    train_df = pd.merge(train_df, stat)\n",
    "\n",
    "for i in range(len(test_stack_list)):\n",
    "    stat = pd.DataFrame(test_stack_list[i], columns = column_name_list[i])\n",
    "    stat['row_id'] = range(stat.shape[0])\n",
    "    test_df = pd.merge(test_df, stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for ML & Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.drop(['created', 'building_id', 'manager_id', 'description', 'row_id', 'display_address', 'features', 'photos', \n",
    "               'street_address', 'train'], axis = 1, inplace = True)\n",
    "\n",
    "test_df.drop(['building_id', 'created', 'description', 'display_address', 'features', \n",
    "               'manager_id', 'photos', 'street_address', 'row_id', 'train'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49352 entries, 0 to 49351\n",
      "Columns: 190 entries, bathrooms to bldg_count_bedrooms_min\n",
      "dtypes: float64(177), int64(12), object(1)\n",
      "memory usage: 71.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74659 entries, 0 to 74658\n",
      "Columns: 189 entries, bathrooms to bldg_count_bedrooms_min\n",
      "dtypes: float64(177), int64(12)\n",
      "memory usage: 108.2 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_json('Datacleaned_FE5_train_withnan.json')\n",
    "test_df.to_json('FE5_test_withnan.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
